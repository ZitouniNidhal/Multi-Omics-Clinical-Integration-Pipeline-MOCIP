# Pipeline d'IntÃ©gration Multi-Omiques

## ğŸ§¬ Description

Ce projet dÃ©veloppe un pipeline modulaire pour l'intÃ©gration de donnÃ©es multi-omiques (transcriptomiques, gÃ©nomiques) avec des donnÃ©es cliniques dans le domaine de la santÃ©. Le pipeline gÃ¨re le nettoyage, la normalisation, l'intÃ©gration et l'export vers des standards d'interopÃ©rabilitÃ© comme FHIR R4.

## ğŸ¯ Objectifs

- **Collecte** : Identifier et tÃ©lÃ©charger des jeux de donnÃ©es biomÃ©dicaux publics (TCGA, GEO)
- **Nettoyage** : GÃ©rer les valeurs manquantes, normaliser les donnÃ©es
- **IntÃ©gration** : Fusionner les donnÃ©es multi-omiques et cliniques
- **Standardisation** : Exporter vers FHIR R4, JSON schÃ©matisÃ©, CSV standardisÃ©
- **QualitÃ©** : Pipeline testÃ©, documentÃ© et prÃªt pour l'IA

## ğŸ“ Structure du Projet

```
projet-multi-omiques/
â”œâ”€â”€ src/                           # Code source
â”‚   â”œâ”€â”€ data_collection/          # Modules de collecte TCGA/GEO
â”‚   â”œâ”€â”€ preprocessing/            # Nettoyage et normalisation
â”‚   â”œâ”€â”€ integration/              # Fusion multi-modalitÃ©s
â”‚   â”œâ”€â”€ standardization/          # Export FHIR/JSON/CSV
â”‚   â”œâ”€â”€ utils/                    # Utilitaires communs
â”‚   â””â”€â”€ pipeline.py               # Pipeline principal
â”œâ”€â”€ data/                         # DonnÃ©es
â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes
â”‚   â”œâ”€â”€ processed/                # DonnÃ©es traitÃ©es
â”‚   â””â”€â”€ external/                 # DonnÃ©es externes
â”œâ”€â”€ notebooks/                    # Notebooks Jupyter
â”œâ”€â”€ tests/                        # Tests unitaires
â”œâ”€â”€ config/                       # Configuration YAML
â”œâ”€â”€ docs/                         # Documentation
â””â”€â”€ logs/                         # Fichiers de log
```

## ğŸš€ Installation et Configuration

### PrÃ©requis

- Python 3.8+
- 4GB RAM minimum
- 10GB d'espace disque

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/votreusername/projet-multi-omiques.git
cd projet-multi-omiques

# 2. CrÃ©er l'environnement virtuel
python -m venv omics_env

# 3. Activer l'environnement
source omics_env/bin/activate  # Linux/Mac
# ou omics_env\Scripts\activate  # Windows

# 4. Installer les dÃ©pendances
pip install -r requirements.txt

# 5. VÃ©rifier l'installation
python -c "from src.pipeline import MultiOmicsPipeline; print('Installation rÃ©ussie!')"
```

### Configuration

Modifier le fichier `config/config.yaml` selon vos besoins :

```yaml
# Configuration principale
general:
  project_name: "multi_omics_pipeline"
  version: "1.0.0"

# ParamÃ¨tres de prÃ©processing
preprocessing:
  missing_values:
    strategy: "knn"  # ou "median", "mean"
    k: 5
  normalization:
    method: "tmm"    # ou "deseq2", "tpm"
```

## ğŸ“Š Utilisation

### DonnÃ©es de DÃ©monstration

Des donnÃ©es de dÃ©monstration sont incluses pour tester le pipeline :

```bash
# DonnÃ©es d'expression gÃ©nique
demo_expression_data.csv     # 10 patients Ã— 5 gÃ¨nes

# DonnÃ©es cliniques
demo_clinical_data.csv       # 10 patients Ã— 5 variables
```

### ExÃ©cution du Pipeline

```bash
# Test avec les donnÃ©es de dÃ©monstration
python src/pipeline.py \
    --omic-data demo_expression_data.csv \
    --clinical-data demo_clinical_data.csv \
    --output-dir results

# Avec des fichiers personnalisÃ©s
python src/pipeline.py \
    --omic-data data/raw/expression_data.csv \
    --clinical-data data/raw/clinical_data.csv \
    --output-dir results
```

### Utilisation comme Module Python

```python
from src.pipeline import MultiOmicsPipeline

# Initialiser le pipeline
pipeline = MultiOmicsPipeline(config_path="config/config.yaml")

# ExÃ©cuter le pipeline
results = pipeline.run(
    omic_data_path="data/raw/expression.csv",
    clinical_data_path="data/raw/clinical.csv",
    output_dir="results"
)

# VÃ©rifier les rÃ©sultats
if results['status'] == 'success':
    print(f"âœ… Pipeline terminÃ© avec succÃ¨s!")
    print(f"ğŸ“ Fichiers de sortie : {results['output_paths']}")
    print(f"ğŸ“ˆ RÃ©sumÃ© : {results['summary']}")
```

## ğŸ”§ Modules Principaux

### 1. Data Collection (`src/data_collection/`)

- **TCGADataCollector** : Collecte des donnÃ©es TCGA via GDC API
- **GEODataCollector** : Collecte des donnÃ©es GEO via NCBI API

### 2. Preprocessing (`src/preprocessing/`)

- **MissingValueHandler** : Gestion des valeurs manquantes (KNN, mÃ©diane)
- **OmicsNormalizer** : Normalisation TMM, DESeq2, TPM
- **QualityControl** : ContrÃ´le qualitÃ© et dÃ©tection d'outliers

### 3. Integration (`src/integration/`)

- **SampleAlignment** : Alignement des Ã©chantillons par ID patient
- **MultiOmicsFusion** : Fusion horizontale des donnÃ©es multi-modalitÃ©s

### 4. Standardization (`src/standardization/`)

- **FHIRExporter** : Export vers format FHIR R4
- **JSONExporter** : Export JSON avec schÃ©ma de validation

## ğŸ“ˆ Tests et Validation

### Tests Unitaires

```bash
# ExÃ©cuter tous les tests
pytest tests/

# Avec couverture
pytest --cov=src tests/

# Test spÃ©cifique
pytest tests/test_preprocessing/test_missing_values.py
```

### Validation des DonnÃ©es

Le pipeline inclut automatiquement :
- Validation de la qualitÃ© des donnÃ©es
- VÃ©rification des formats d'export
- Tests de cohÃ©rence post-intÃ©gration

## ğŸ“Š Visualisations

Des notebooks Jupyter sont inclus pour l'exploration des donnÃ©es :

- `notebooks/01_data_exploration.ipynb` : Analyse exploratoire complÃ¨te
- `notebooks/02_data_cleaning_demo.ipynb` : DÃ©monstration du nettoyage
- `notebooks/03_data_integration_demo.ipynb` : DÃ©monstration de l'intÃ©gration

## ğŸ”¬ Jeux de DonnÃ©es RecommandÃ©s

### Pour le dÃ©veloppement

- **TCGA-BRCA** : Cancer du sein (1,221 Ã©chantillons)
- **GEO GSE96058** : Cancer du sein mÃ©tastatique (563 Ã©chantillons)

### Pour la validation

- **ICGC** : International Cancer Genome Consortium
- **ArrayExpress** : Archive de donnÃ©es de puces Ã  ADN

## ğŸ“¤ Formats de Sortie

### FHIR R4

Export conforme au standard HL7 FHIR R4 :
- Ressources Patient, Observation, DiagnosticReport
- Validation du schÃ©ma FHIR
- Support des ontologies LOINC/HGNC

### JSON SchÃ©matisÃ©

Format JSON avec schÃ©ma de validation :
- MÃ©tadonnÃ©es complÃ¨tes
- TraÃ§abilitÃ© des transformations
- Validation automatique

### CSV StandardisÃ©

Format CSV avec conventions :
- SÃ©parateur tabulation
- En-tÃªtes standardisÃ©s
- Documentation des colonnes

## ğŸ› ï¸ DÃ©veloppement

### Architecture

Le pipeline suit une architecture modulaire :

```python
# Exemple de module
def process_data(self, data, config):
    """Process data with configuration"""
    # Validation
    if not self.validate_input(data):
        raise ValueError("Invalid input data")
    
    # Traitement
    processed = self.apply_transformation(data, config)
    
    # VÃ©rification
    if not self.validate_output(processed):
        raise ValueError("Invalid output data")
    
    return processed
```

### Ajout de Nouveaux Modules

1. CrÃ©er le module dans `src/nouveau_module/`
2. ImplÃ©menter l'interface standard
3. Ajouter les tests unitaires
4. Documenter l'utilisation
5. Mettre Ã  jour la configuration

## ğŸ“š Documentation

### Documentation Technique

- **API Reference** : Docstrings complÃ¨tes
- **Architecture** : Diagrammes de flux
- **Standards** : ConformitÃ© FHIR R4

### Guides d'Utilisation

- **Guide de dÃ©marrage rapide** : 5 minutes pour dÃ©marrer
- **Tutoriels** : Exemples pas Ã  pas
- **FAQ** : Questions frÃ©quentes

## ğŸ¤ Contribution

### Processus de Contribution

1. Fork le repository
2. CrÃ©er une branche (`feature/nouvelle-fonctionnalitÃ©`)
3. Commit les changements
4. Push vers la branche
5. CrÃ©er une Pull Request

### Standards de Code

- **Style** : PEP 8
- **Tests** : Couverture >90%
- **Documentation** : Docstrings obligatoires
- **Review** : Code review avant merge

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **TCGA** : The Cancer Genome Atlas
- **GEO** : Gene Expression Omnibus
- **HL7 FHIR** : Standard d'interopÃ©rabilitÃ©
- **Python Community** : Ã‰cosystÃ¨me scientifique

## ğŸ“ Support

Pour toute question ou problÃ¨me :

- **Documentation** : Voir `docs/`
- **Issues** : GitHub Issues
- **Email** : votre.email@example.com

---

**ğŸ§¬ Pipeline Multi-Omiques - IntÃ©gration intelligente pour la mÃ©decine de prÃ©cision**